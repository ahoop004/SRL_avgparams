wandb:
  project_name: "sumo-rl"  
  entity: "researchlab-yr404"
  name: "avg_params"
  group: "Marl-avg_params"
  sweep_config:
    method: grid  # or 'grid', 'bayes'
    metric:
      name: episode_reward
      goal: maximize
    parameters:
      agent_hyperparameters.seed:
        values: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]
      # agent_hyperparameters.gamma:
      #   values: [0.95, 0.99, 0.999]
      # agent_hyperparameters.epsilon_decay:
      #   values: [0.995, 0.999, 0.9995, 0.9999]
      # agent_hyperparameters.batch_size:
      #   values: [32, 64, 128]
      # agent_hyperparameters.memory_size:
      #   values: [5000, 10000, 50000]
      # per_hyperparameters.alpha:
      #   values: [0.4, 0.6, 0.8]
      # per_hyperparameters.beta:
      #   values: [0.4, 0.6, 0.8]
      # per_hyperparameters.priority_epsilon:
      #   values: [0.0001, 0.001, 0.01]

# Training settings
training_settings:
  episodes: 15000             
  experiment_path: 'data/balt/'
  sumoconfig: "Nets/osm.sumocfg"
  savepath: "models/" 
  loadpath: "models/"                        
  initial_life: .1                    
  penalty: -0.2 
  seed: 1

# Environment settings
env:
  num_of_agents: 2  # Number of community vehicles                  
  num_of_people: 5  # Number of passengers per episode            
  types_of_passengers: 2
  num_agents: 2

# Agent hyperparameters
agent_hyperparameters:
  learning_rate: 0.00001
  gamma: 0.999            
  epsilon_decay: 0.9996
  batch_size: 128
  memory_size: 50000
  epsilon_max: 1.0
  epsilon_min: 0.05                   
  penalty: -0.2  

# Priority Experience Replay hyperparameters
per_hyperparameters:
  alpha: 0.6
  beta: 0.4
  priority_epsilon: 0.00001
